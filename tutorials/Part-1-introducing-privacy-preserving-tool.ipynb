{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we perform statistical analysis/train models on sensitive or private data?\n",
    "\n",
    "Is it possible to want to protect privacy and still perform predictive analysis on these private data, you most likely would say thats's not possible simply because the traditional data science process involves first collecting various data from diverse sources into one server or location and then perform training or analysis on those data. in this tutorial, we're going to look into tools and techniques required to answer questions on data we do not own locally or have access to due to privacy concerns but would still love to perform analysis on them. \n",
    "\n",
    "More specifically, we are going to look at the basics pysyft which is an open-source tool built on top of pytorch and tensorflow for computing over information you do not own on machines you do not have control over. Pysyft helps keep data at their edge locations while still allowing for computation over the data in a decentralized manner. This tutorial take a practical coding-based approach, and the best way to learn the material is to execute the code cell by cell and experiment with the examples.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "- Familiarity with pytorch [check the 60-minute blitz pytorch official tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup \n",
    "\n",
    "## How to run the code\n",
    "\n",
    "This notebook was developed on [Jovian.ml](https://www.jovian.ml), a platform for sharing data science projects online. You can \"run\" this tutorial and experiment with the code examples in a couple of ways: *using free online resources* (recommended) or *on your own computer*.\n",
    "\n",
    "### Option 1: Running using free online resources (1-click, recommended)\n",
    "\n",
    "The easiest way to start executing this notebook is to click the \"Run\" button at the top of the jovian page [via this link](https://jovian.ai/tifeasypeasy/introducing-privacy-preserving-tool), and select \"Run on Binder\". This will run the notebook on [mybinder.org](https://mybinder.org), a free online service for running Jupyter notebooks. You can also select \"Run on Colab\" or \"Run on Kaggle\", but you'll need to create an account on [Google Colab](https://colab.research.google.com) or [Kaggle](https://kaggle.com) to use these platforms.\n",
    "\n",
    "\n",
    "### Option 2: Running on your computer locally\n",
    "\n",
    "You'll need to install Python and download this notebook on your computer to run it locally. I recommend using the [Conda](https://docs.conda.io/en/latest/) distribution of Python. Here's what you need to do to get started:\n",
    "\n",
    "1. Install Conda by [following these instructions](https://github.com/Boluwatifeh/Secure-AI/blob/master/INSTALLATION.md). Make sure to add Conda binaries to your system `PATH` to be able to run the `conda` command line tool from your Mac/Linux terminal or Windows command prompt. \n",
    "\n",
    "\n",
    "2. Create and activate a [Conda virtual environment](https://github.com/Boluwatifeh/Secure-AI/blob/master/INSTALLATION.md) called `my_env` which you can use for this tutorial series:\n",
    "```\n",
    "conda create -n my_env python=3.6 \n",
    "conda activate my_env\n",
    "```\n",
    "You'll need to create the environment only once, but you'll have to activate it every time want to run the notebook. When the environment is activated, you should be able to see a prefix `(my_env)` within your terminal or command prompt.\n",
    "\n",
    "\n",
    "3. Install the required Python libraries within the environmebt by the running the following command on your  terminal or command prompt:\n",
    "```\n",
    "conda install jupyter notebook\n",
    "pip install syft\n",
    "```\n",
    "If you're facing some issues installing syft locally, kindly skip the `pip install syft` command and move on as there is a room for installing syft via the jupyter notebook.\n",
    "\n",
    "4. Clone this repository on github \n",
    "```\n",
    "git clone https://github.com/Boluwatifeh/Secure-AI.git\n",
    "```\n",
    "\n",
    "5. Enter the project directory and start the Jupyter notebook:\n",
    "```\n",
    "cd tutorials\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "6. You can now access Jupyter's web interface by clicking the link that shows up on the terminal or by visiting http://localhost:8888 on your browser. Click on the notebook `introducing-privacy-preserving-tool.ipynb` to open it and run the code. If you want to type out the code yourself, you can also create a new notebook using the \"New\" button.\n",
    "\n",
    "For some reason if any part of the above iinstruction doesn't work, first check INSTALLATION.md for help, and then open a GitHub Issue. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ways of preserving privacy \n",
    "\n",
    "## 1. Data anonymization\n",
    "Data anonymization is the process of protecting private or sensitive information by erasing or encrypting identifiers that  connect an individual to stored data. For example, you can run Personally Identifiable Information(PII) such as names, social security numbers and addresses through a data anonymization process that retains the data but keeps the source anonymous. As much as this technique seem to protect privacy to some level, it is still very much not advisable to implement as we have seen several cases of data de-anonymization on anonymized data. Some studies have shown that it's quite easy to de-anonymize anonymized data an example is in the Netflix prize competition where a team was asked to build a movie recommendation system with an anonymized dataset of over one hundred million movie ratings from half a million users so that individual team participating in the competition could train their models. Later sometime, two researchers were able to de-anonymize the name of the movies and the users on the ratings with the anonymized data.\n",
    "\n",
    "# Disadvantages \n",
    "- If there's a case of two related anonymized datasets, its very possible to de-anonymize the datasets and invade privacy  by studying the two datasets and looking for correlation between them.\n",
    "- Collecting data and performing anonymization on the dataset limits ability to derive value and insight from such data therefore users experience cannot be personalized in the case of anonymized datasets.\n",
    "\n",
    "![](https://github.com)\n",
    "\n",
    "## 2. Federated learning \n",
    "The simplest way to protect privacy of data is not to collect the data in the first instance. As we can see in the case of data anonymization, it doesn't work but without collecting the data, we can't perform analysis or train a model. So how do we fix that ? Federated learning is a machine learning setting where many clients(e.g mobile devices or a whole organization) collaboratively train a model under the orchestration of a central server while keeping the training data decentralized. It embodies the principles of focused collection and data minimization and can mitigate many of the systematic privacy risks and costs resulting from traditional, centralized machine learning.\n",
    "\n",
    "![](https://github.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing PySyft\n",
    "We are going to use an open source library called PySyft to implement federated learning that we just dicussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing libraries\n",
    "The jovian library allows us to commit our notebook to the jovian platform which is a data science collaboration and sharing platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jovian --upgrade --quiet\n",
    "# uncomment the above command if youre running on binder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting syft\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/73/891ba1dca7e0ba77be211c36688f083184d8c9d5901b8cd59cbf867052f3/syft-0.2.9-py3-none-any.whl (433kB)\n",
      "\u001b[K     |████████████████████████████████| 440kB 3.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Flask~=1.1.1 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 8.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting lz4~=3.0.2 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/38/dacc3cbb33a9ded9e2e57f48707e8842f1080997901578ebddaa0e031646/lz4-3.0.2-cp37-cp37m-manylinux2010_x86_64.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 11.4MB/s eta 0:00:01     |████████████▎                   | 675kB 11.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting syft-proto~=0.5.2 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/85/fea3668a2da78b02394bd2532e6c8b01f354c664f09db74d7f133b68f938/syft_proto-0.5.2-py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 23.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill~=0.3.1 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/96/518a8ea959a734b70d2e95fef98bcbfdc7adad1c1e5f5dd9148c835205a5/dill-0.3.2.zip (177kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 25.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests~=2.22.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from syft) (2.22.0)\n",
      "Collecting RestrictedPython~=5.0 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/cc/28c4d966615a46b03be4dac0f2c6e713412efbf2f85428eeb9618c4f6f0c/RestrictedPython-5.1-py2.py3-none-any.whl\n",
      "Collecting openmined.threepio==0.2.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/38/df6367693c7f3808f076cd8c2647c434a04adda2bbb2435dadefe7258fd4/openmined.threepio-0.2.0.tar.gz (73kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 16.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websocket-client~=0.57.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 13.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources~=1.5.0 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/2d/88f166bcaadc09d9fdbf1c336ad118e01b7fe1155e15675e125be2ff1899/importlib_resources-1.5.0-py2.py3-none-any.whl\n",
      "Collecting torchvision~=0.5.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1c/32/cb0e4c43cd717da50258887b088471568990b5a749784c465a8a1962e021/torchvision-0.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.0MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0MB 22.3MB/s eta 0:00:01     |████████████████████████████    | 3.5MB 22.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-toolbelt==0.9.1 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 9.4MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting msgpack~=1.0.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/9f/5a6805e7e745531da7acc882f9ba4550ffd7d6f05a668a22b385f52741ee/msgpack-1.0.0-cp37-cp37m-manylinux1_x86_64.whl (275kB)\n",
      "\u001b[K     |████████████████████████████████| 276kB 25.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting psutil==5.7.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/b8/3512f0e93e0db23a71d82485ba256071ebef99b227351f0f5540f744af41/psutil-5.7.0.tar.gz (449kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting websockets~=8.1.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 19.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: notebook==5.7.8 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from syft) (5.7.8)\n",
      "Collecting aiortc==0.9.28 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/c5/0c15e562c5ea1531e8c7db1bcd524e53619cc27a228f3f28d2ba55544d38/aiortc-0.9.28-cp37-cp37m-manylinux2010_x86_64.whl (2.0MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0MB 45.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow>=7.1.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/fa/c1302a26d5e1a17fa8e10e43417b6cf038b0648c4b79fcf2302a4a0c5d30/Pillow-8.0.1-cp37-cp37m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 28.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flask-socketio~=4.2.1 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/66/44/edc4715af85671b943c18ac8345d0207972284a0cd630126ff5251faa08b/Flask_SocketIO-4.2.1-py2.py3-none-any.whl\n",
      "Collecting tornado==4.5.3 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/7b/e29ab3d51c8df66922fea216e2bddfcb6430fb29620e5165b16a216e0d3c/tornado-4.5.3.tar.gz (484kB)\n",
      "\u001b[K     |████████████████████████████████| 491kB 24.8MB/s eta 0:00:01     |██████████▉                     | 163kB 24.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting phe~=1.4.0 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/32/0e/568e97b014eb14e794a1258a341361e9da351dc6240c63b89e1541e3341c/phe-1.4.0.tar.gz\n",
      "Collecting shaloop==0.2.1-alpha.11 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/8e/6c4493280d55199161c2eea896327c740195cf16cc74c5393c08eababc83/shaloop-0.2.1_alpha.11-py3-none-manylinux1_x86_64.whl (126kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 41.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy~=1.4.1 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/82/c1fe128f3526b128cfd185580ba40d01371c5d299fcf7f77968e22dfcc2e/scipy-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (26.1MB)\n",
      "\u001b[K     |████████████████████████████████| 26.1MB 23.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tblib~=1.6.0 (from syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/de/dca3e651ca62e59c08d324f4a51467fa4b8cbeaafb883b5e83720b4d4a47/tblib-1.6.0-py2.py3-none-any.whl\n",
      "Collecting torch~=1.4.0 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/3b/fa92ece1e58a6a48ec598bab327f39d69808133e5b2fb33002ca754e381e/torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 25kB/s s eta 0:00:019MB 34.6MB/s eta 0:00:21     |██▋                             | 61.5MB 36.5MB/s eta 0:00:19     |████                            | 92.5MB 39.0MB/s eta 0:00:17     |████                            | 95.0MB 39.0MB/s eta 0:00:17��█████                       | 209.3MB 37.9MB/s eta 0:00:15     |████████████▍                   | 291.5MB 36.7MB/s eta 0:00:13          | 351.1MB 44.7MB/s eta 0:00:09��███████████████             | 444.9MB 57.1MB/s eta 0:00:06MB/s eta 0:00:06     |████████████████████            | 472.5MB 57.1MB/s eta 0:00:05 eta 0:00:05��██████████▏           | 475.3MB 19.0MB/s eta 0:00:15██████████████████▎           | 476.5MB 19.0MB/s eta 0:00:15███████████████▋          | 508.9MB 56.6MB/s eta 0:00:05     |████████████████████████▉       | 585.0MB 36.1MB/s eta 0:00:05�███████████▉       | 585.2MB 36.1MB/s eta 0:00:05    | 587.1MB 36.1MB/s eta 0:00:05█████       | 589.5MB 53.0MB/s eta 0:00:04     |█████████████████████████       | 590.8MB 53.0MB/s eta 0:00:04B 53.0MB/s eta 0:00:04     |█████████████████████████▎      | 595.2MB 53.0MB/s eta 0:00:03597.7MB 53.0MB/s eta 0:00:03███████████▍      | 598.5MB 53.0MB/s eta 0:00:03 0:00:03��█▊      | 604.5MB 53.0MB/s eta 0:00:03��██████████████████      | 611.3MB 53.0MB/s eta 0:00:03     |██████████████████████████      | 613.0MB 2.7MB/s eta 0:00:52     |██████████████████████████▏     | 614.8MB 2.7MB/s eta 0:00:51     |██████████████████████████▏     | 616.1MB 2.7MB/s eta 0:00:51�█████████▎    | 641.8MB 2.7MB/s eta 0:00:41     |███████████████████████████▎    | 643.3MB 1.3MB/s eta 0:01:27�████████▍    | 644.2MB 1.3MB/s eta 0:01:27��████████▍    | 644.9MB 1.3MB/s eta 0:01:26     |███████████████████████████▌    | 647.5MB 1.3MB/s eta 0:01:24    |████████████████████████████▋   | 673.7MB 1.3MB/s eta 0:01:03[K     |████████████████████████████▊   | 676.1MB 2.8MB/s eta 0:00:28�████████▊   | 677.2MB 2.8MB/s eta 0:00:28█████████   | 680.5MB 2.8MB/s eta 0:00:27��████████   | 680.8MB 2.8MB/s eta 0:00:27     |█████████████████████████████▏  | 686.5MB 2.8MB/s eta 0:00:25��█████████████████▎  | 688.7MB 2.8MB/s eta 0:00:24█████████▌  | 695.6MB 2.8MB/s eta 0:00:21███████████████████▋  | 697.8MB 36.9MB/s eta 0:00:02██████████████████████▉ | 727.1MB 36.9MB/s eta 0:00:01 0:00:01 |███████████████████████████████▊| 745.9MB 17.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.18.1 (from syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K     |████████████████████████████████| 20.1MB 41.9MB/s eta 0:00:01K     |▌                               | 307kB 41.9MB/s eta 0:00:01█▍                              | 870kB 41.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Werkzeug>=0.15 (from Flask~=1.1.1->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/94/5f7079a0e00bd6863ef8f1da638721e9da21e5bacee597595b318f71d62e/Werkzeug-1.0.1-py2.py3-none-any.whl (298kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 43.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from Flask~=1.1.1->syft) (2.10.1)\n",
      "Collecting itsdangerous>=0.24 (from Flask~=1.1.1->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: click>=5.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from Flask~=1.1.1->syft) (7.1.2)\n",
      "Collecting protobuf>=3.12.2 (from syft-proto~=0.5.2->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/dc/5ba56eab7440c62c5f808b4267e2a1d6c136e90293b43fefb1b493c6d704/protobuf-3.13.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 29.1MB/s eta 0:00:01��████████                    | 481kB 29.1MB/s eta 0:00:01███████▉          | 870kB 29.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests~=2.22.0->syft) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests~=2.22.0->syft) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests~=2.22.0->syft) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from requests~=2.22.0->syft) (1.25.3)\n",
      "Requirement already satisfied: six in /srv/conda/envs/notebook/lib/python3.7/site-packages (from websocket-client~=0.57.0->syft) (1.12.0)\n",
      "Collecting zipp>=0.4; python_version < \"3.8\" (from importlib-resources~=1.5.0->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/41/ad/6a4f1a124b325618a7fb758b885b68ff7b058eec47d9220a12ab38d90b1f/zipp-3.4.0-py3-none-any.whl\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from importlib-resources~=1.5.0->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/6d/f4bb28424bc677bce1210bc19f69a43efe823e294325606ead595211f93e/importlib_metadata-2.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: nbformat in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (4.4.0)\n",
      "Requirement already satisfied: ipykernel in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (5.1.1)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (0.8.2)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (5.3.1)\n",
      "Requirement already satisfied: nbconvert in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (5.4.1)\n",
      "Requirement already satisfied: ipython-genutils in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (0.2.0)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (4.4.0)\n",
      "Requirement already satisfied: Send2Trash in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (1.5.0)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (4.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (18.0.2)\n",
      "Requirement already satisfied: prometheus-client in /srv/conda/envs/notebook/lib/python3.7/site-packages (from notebook==5.7.8->syft) (0.7.1)\n",
      "Collecting pyee>=6.0.0 (from aiortc==0.9.28->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/0a/933b3931107e1da186963fd9bb9bceb9a613cff034cb0fb3b0c61003f357/pyee-8.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cryptography>=2.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from aiortc==0.9.28->syft) (2.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from aiortc==0.9.28->syft) (1.12.3)\n",
      "Collecting pylibsrtp>=0.5.6 (from aiortc==0.9.28->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/1a/6d4810815b2309b6af2de888bb66daa2fdf7b550aac262fd7af0b0a78e6b/pylibsrtp-0.6.7-cp37-cp37m-manylinux2010_x86_64.whl (75kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 12.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aioice<0.7.0,>=0.6.17 (from aiortc==0.9.28->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/8b/86/e3cdf660b67da7a9a7013253db5db7cf786a52296cb40078db1206177698/aioice-0.6.18-py3-none-any.whl\n",
      "Collecting crc32c (from aiortc==0.9.28->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/85/4656cc0ac33be2725d6de41eabfeb72f86c194fe26decf28162d72f9a642/crc32c-2.2-cp37-cp37m-manylinux2010_x86_64.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 15.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting av<9.0.0,>=8.0.0 (from aiortc==0.9.28->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/e0/55d9226e852a03de215167ba3948432347a23a44d9f8e3bd7a6f219658c3/av-8.0.2-cp37-cp37m-manylinux2010_x86_64.whl (36.9MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 36.9MB 32.1MB/s eta 0:00:01B/s eta 0:00:030:03�▉                            | 4.4MB 15.0MB/s eta 0:00:03MB/s eta 0:00:02| 9.9MB 15.0MB/s eta 0:00:02 10.4MB 15.0MB/s eta 0:00:02MB 15.0MB/s eta 0:00:02     |████████████▌                   | 14.4MB 15.0MB/s eta 0:00:02█████            | 22.9MB 32.1MB/s eta 0:00:01��███████████▎           | 23.3MB 32.1MB/s eta 0:00:01��█████████████████▌          | 24.8MB 32.1MB/s eta 0:00:0100:01\n",
      "\u001b[?25hCollecting python-socketio>=4.3.0 (from flask-socketio~=4.2.1->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/97/00741edd49788510b834b60a1a4d0afb2c4942770c11b8e0f6e914371718/python_socketio-4.6.0-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 12.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pycparser>=2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from shaloop==0.2.1-alpha.11->syft) (2.19)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from Jinja2>=2.10.1->Flask~=1.1.1->syft) (1.1.1)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.7/site-packages (from protobuf>=3.12.2->syft-proto~=0.5.2->syft) (41.0.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbformat->notebook==5.7.8->syft) (3.0.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipykernel->notebook==5.7.8->syft) (7.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jupyter-client>=5.2.0->notebook==5.7.8->syft) (2.8.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (0.8.4)\n",
      "Requirement already satisfied: pygments in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (2.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (0.3)\n",
      "Requirement already satisfied: bleach in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (3.1.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (1.4.2)\n",
      "Requirement already satisfied: testpath in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (0.4.2)\n",
      "Requirement already satisfied: defusedxml in /srv/conda/envs/notebook/lib/python3.7/site-packages (from nbconvert->notebook==5.7.8->syft) (0.5.0)\n",
      "Requirement already satisfied: decorator in /srv/conda/envs/notebook/lib/python3.7/site-packages (from traitlets>=4.2.1->notebook==5.7.8->syft) (4.4.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from cryptography>=2.2->aiortc==0.9.28->syft) (0.24.0)\n",
      "Collecting netifaces (from aioice<0.7.0,>=0.6.17->aiortc==0.9.28->syft)\n",
      "  Downloading https://files.pythonhosted.org/packages/0d/18/fd6e9c71a35b67a73160ec80a49da63d1eed2d2055054cc2995714949132/netifaces-0.10.9.tar.gz\n",
      "Collecting python-engineio>=3.13.0 (from python-socketio>=4.3.0->flask-socketio~=4.2.1->syft)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/b0/602e549c6d735eb487f186b35e0b82e61c89459f57d1c24d5c7be6f56d05/python_engineio-3.13.2-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 17.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook==5.7.8->syft) (19.1.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat->notebook==5.7.8->syft) (0.15.4)\n",
      "Requirement already satisfied: pickleshare in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.7.5)\n",
      "Requirement already satisfied: backcall in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.1.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.14.1)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (2.0.9)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /srv/conda/envs/notebook/lib/python3.7/site-packages (from ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (4.7.0)\n",
      "Requirement already satisfied: webencodings in /srv/conda/envs/notebook/lib/python3.7/site-packages (from bleach->nbconvert->notebook==5.7.8->syft) (0.5.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.5.1)\n",
      "Requirement already satisfied: wcwidth in /srv/conda/envs/notebook/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel->notebook==5.7.8->syft) (0.6.0)\n",
      "Building wheels for collected packages: dill, openmined.threepio, psutil, tornado, phe, netifaces\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.2-cp37-none-any.whl size=78912 sha256=baf22247c8d50f34c74ebcf1922a6bb3f3b2487b8053f2130a79046864aff0ea\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/27/4b/a2/34ccdcc2f158742cfe9650675560dea85f78c3f4628f7daad0\n",
      "  Building wheel for openmined.threepio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openmined.threepio: filename=openmined.threepio-0.2.0-cp37-none-any.whl size=80095 sha256=d208e4610d7a6983524636044e13da7f1387116d3e5b82007855f78c5c5de41e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/1b/a5/c5/7e67449f5d4d487e1d3a583ba51d27403b315b18ef2e48a13c\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp37-cp37m-linux_x86_64.whl size=276464 sha256=149d2fcbf5778808809cd5f84c0067d816281725f9c34ea133e704452185cfa9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d7/69/b4/3200b95828d1f0ddb3cb5699083717f4fdbd9b4223d0644c57\n",
      "  Building wheel for tornado (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tornado: filename=tornado-4.5.3-cp37-cp37m-linux_x86_64.whl size=434095 sha256=534a0137aa056be253af65ddd9a25e8a2f1135f2bfdac566f42e8512c2876a96\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/72/bf/f4/b68fa69596986881b397b18ff2b9af5f8181233aadcc9f76fd\n",
      "  Building wheel for phe (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for phe: filename=phe-1.4.0-py2.py3-none-any.whl size=37361 sha256=27eba7635c02fe42da13efb4ada83ecf45b4b50e218c074abcef893e64348e6a\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/f8/dc/36/dcb6bf0f1b9907e7b710ace63e64d08e7022340909315fdea4\n",
      "  Building wheel for netifaces (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for netifaces: filename=netifaces-0.10.9-cp37-cp37m-linux_x86_64.whl size=37335 sha256=3ee5dd84c0ebfbc49cd8a684e7ea31984877a84d870d2c4678aa6ca423045760\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/23/8f/f3/7054578f04c904f70757c5c85a6e2823baa69d42365526e93d\n",
      "Successfully built dill openmined.threepio psutil tornado phe netifaces\n",
      "\u001b[31mERROR: jupyterhub 1.0.0 has requirement tornado>=5.0, but you'll have tornado 4.5.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Werkzeug, itsdangerous, Flask, lz4, protobuf, syft-proto, dill, RestrictedPython, openmined.threepio, websocket-client, zipp, importlib-metadata, importlib-resources, numpy, Pillow, torch, torchvision, requests-toolbelt, msgpack, psutil, websockets, pyee, pylibsrtp, netifaces, aioice, crc32c, av, aiortc, python-engineio, python-socketio, flask-socketio, tornado, phe, shaloop, scipy, tblib, syft\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Found existing installation: tornado 6.0.3\n",
      "    Uninstalling tornado-6.0.3:\n",
      "      Successfully uninstalled tornado-6.0.3\n",
      "Successfully installed Flask-1.1.2 Pillow-8.0.1 RestrictedPython-5.1 Werkzeug-1.0.1 aioice-0.6.18 aiortc-0.9.28 av-8.0.2 crc32c-2.2 dill-0.3.2 flask-socketio-4.2.1 importlib-metadata-2.0.0 importlib-resources-1.5.0 itsdangerous-1.1.0 lz4-3.0.2 msgpack-1.0.0 netifaces-0.10.9 numpy-1.18.5 openmined.threepio-0.2.0 phe-1.4.0 protobuf-3.13.0 psutil-5.7.0 pyee-8.1.0 pylibsrtp-0.6.7 python-engineio-3.13.2 python-socketio-4.6.0 requests-toolbelt-0.9.1 scipy-1.4.1 shaloop-0.2.1a11 syft-0.2.9 syft-proto-0.5.2 tblib-1.6.0 torch-1.4.0 torchvision-0.5.0 tornado-4.5.3 websocket-client-0.57.0 websockets-8.1 zipp-3.4.0\n"
     ]
    }
   ],
   "source": [
    "# this installs the syft library, comment the below command if you were able to install syft locally\n",
    "!pip install syft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and initializing hook \n",
    "Lets import torch and initialize the hook. The hook is to override pytorch's methods in order to execute commands on workers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import syft as sy\n",
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  4,  6,  8, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5])\n",
    "y = x + x\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least the above code looks familiar its just a normal pytorch arithmetic which involves we having the data locally, but then how can we perform this kind of basic arithmetic on a machine we do not own or have access to?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a remote machine(worker)\n",
    "Before we can perform any computation on  a remote machine, we need to have an interface that connects us to that machine. Let us explore one of the functionality of syft by creating a pretend machine which belongs to Joe and send some data over to perform basic arithmetic.\n",
    "\n",
    "At this point we would no longer be dealing with the normal pytorch tensors alone but **pointers** to tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe has:{}\n"
     ]
    }
   ],
   "source": [
    "joe = sy.VirtualWorker(hook, id=\"joe\")\n",
    "print('Joe has:' + str(joe._objects)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over here we have Joe which is a worker, let's create some  tensors and send them to Joe as it appears Joe is an empty machine right now without any data on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:45439385298 -> joe:25448987438]\n",
      "(Wrapper)>[PointerTensor | me:46984909473 -> joe:44741931737]\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5])\n",
    "y = torch.tensor([1,1,1,1,1])\n",
    "# sending tensors to joe\n",
    "x = x.send(joe)\n",
    "y = y.send(joe)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, after sending those tensors to Joe what was returned is a PointerTensor to that tensor sent and this would be the basics of execution as the pointer holds information about the tensor we sent earlier.  We can use the ._objects attribute to view the tensor sent to Joe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe has{25448987438: tensor([1, 2, 3, 4, 5]), 44741931737: tensor([1, 1, 1, 1, 1])}\n"
     ]
    }
   ],
   "source": [
    "print('Joe has' + str(joe._objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: PointerTensor usually don't hold data themselves,  they rather contain metadata about a tensor stored on another machine.The purpose of the PointerTensor is to give us an interface to tell the other machine to compute functions using this tensor.\n",
    "\n",
    "Let's view the metadata that pointers consist of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Wrapper)>[PointerTensor | me:45439385298 -> joe:25448987438]\n",
      "(Wrapper)>[PointerTensor | me:46984909473 -> joe:44741931737]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main attributes specific to pointers:\n",
    "\n",
    "- `x.location : ` the location, a reference to the location that the pointer is pointing to\n",
    "- `x.id_at_location : <random integer>`, the id where the tensor is stored at location\n",
    "\n",
    "There are also other more generic attributes:\n",
    "- `x.id : <random integer>`, the id of our pointer tensor, it was allocated randomly\n",
    "- `x.owner : \"me\"`, the worker which owns the pointer tensor, here it's the local worker, named \"me\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:joe #objects:2>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:joe #objects:2>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joe == x.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25448987438"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.id_at_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:me #objects:0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.owner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've sent some data to the remote machine for commputation, how do we get this data back after computation is done you might ask, we can use the get() method to get back the data sent which in this case is x from Joe's machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([1, 1, 1, 1, 1])\n",
      "Joe has:{}\n"
     ]
    }
   ],
   "source": [
    "x = x.get()\n",
    "y=y.get()\n",
    "print(x)\n",
    "print(y)\n",
    "print('Joe has:' + str(joe._objects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, after getting the data from joe's machine the data now returns to our machine and joe no longer has the tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing remote arithmetic operations\n",
    "As we have seen earlier in the introduction to pysyft, we were able to create torch tensors and perform arithmetic. Same thing applies with remote tensors too, we can perform arithmetic operations using syft on remote tensors just like we normally do with pytorch while still having full access to pytorch functions including backpropagation. Let's look at some basic arithmetic operation on PointerTensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4,5]).send(joe)\n",
    "y = torch.tensor([1,1,1,1,1]).send(joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:11310952391 -> joe:26732459988]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would assume, z returns a PointerTensor and the get method returns the output of the operation tensors back to us simply because the execution was not done locally, instead was carried out on joe's machine therefore we need to use the get() method in order to get back the resulting tensors "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch functions and Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Wrapper)>[PointerTensor | me:34301111294 -> joe:78664832368],\n",
       " (Wrapper)>[PointerTensor | me:3293199719 -> joe:90815115877])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:5774831528 -> joe:68221850279]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syft API give us access to torch functions and makes the whole operation seem torch like, it also supports backpropagation and many other functionalities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1,2,3,4,5.], requires_grad=True).send(joe)\n",
    "y = torch.tensor([1,1,1,1,1.], requires_grad=True).send(joe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x + y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:28251579733 -> joe:6502340217]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5.], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "And this brings us to the end of the tutorial and i hope you have been able to have a grasp of the pysyft library for basic remote execution. There are much more advanced technique we can implement with pysyft other than federated learning such as secure multiparty computation and differential privacy, unfortunately we won't be able to cover that in this tutorial but you can always check the openmined community on github.\n",
    "\n",
    "## Learn more \n",
    "- Star the pysyft library on github\n",
    "- Sign up for a free udacity course developed by the openmined team [udacity secure and private AI course](https://www.udacity.com/course/secure-and-private-ai--ud185)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and upload your notebook\n",
    "\n",
    "Whether you're running this Jupyter notebook on an online service like Binder or on your local machine, it's important to save your work from time, so that you can access it later, or share it online. You can upload this notebook to your [Jovian.ml](https://jovian.ml) account using the `jovian` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the jovian library\n",
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'introducing privacy preserving tool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Attempting to save notebook..\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(project=project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time you run `jovian.commit`, you'll be asked to provide an API Key, to securely upload the notebook to your Jovian.ml account. You can get the API key from your Jovian.ml profile page after logging in / signing up.\n",
    "\n",
    "![api-key](https://github.com/Boluwatifeh/Secure-AI/blob/master/images/api-image.png)\n",
    "\n",
    "`jovian.commit` uploads the notebook to your Jovian.ml account, captures the Python environment and creates a shareable link for your notebook as shown above. You can use this link to share your work and let anyone (including you) run your notebooks and reproduce your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
